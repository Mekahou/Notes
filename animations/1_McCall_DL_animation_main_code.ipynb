{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697010c1-bf3f-46e1-9c92-7f11aa2b3bf0",
   "metadata": {},
   "source": [
    "**From a series of application of modern interpolation methods for economics: written by [Mahdi E Kahou](https://sites.google.com/site/mahdiebrahimikahou/about-me)**\n",
    "\n",
    "This code is for generating the plots and animations.\n",
    "\n",
    "The explanation and main code can be found in this [Notebook](https://github.com/Mekahou/Notes/blob/main/deep_learning/McCall_DL.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7697986-8e0b-4ba7-ae30-30b2eda1e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24f09ce-faf5-4174-a995-14e22c88a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "\n",
    "# For closed-form solution\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb59c1ac-232a-4f92-8306-289c7d1711ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize= 14\n",
    "ticksize = 14\n",
    "figsize = (8, 6)\n",
    "params_fig = {'font.family':'serif',\n",
    "    \"figure.figsize\":figsize,\n",
    "    'figure.dpi': 80,\n",
    "    'figure.edgecolor': 'k',\n",
    "    'font.size': fontsize,\n",
    "    'axes.labelsize': fontsize,\n",
    "    'axes.titlesize': fontsize,\n",
    "    'xtick.labelsize': ticksize,\n",
    "    'ytick.labelsize': ticksize\n",
    "}\n",
    "plt.rcParams.update(params_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc1f99-efe0-4ee5-bfb3-bcd7a110b3f7",
   "metadata": {},
   "source": [
    "## Closed form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84492672-b5d3-49c4-ba63-cbd883cf89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 0.5\n",
    "c = 0.05\n",
    "β = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aafdbf5-95b6-4ed4-94c4-fe1a9a42a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDF of wages uniformly distributed on [0, B]\n",
    "f = lambda w: 1/B if 0 <= w <= B else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07b21ba-4d19-4054-b7ed-d362fb57a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indifference(w):\n",
    "    LHS = w-c\n",
    "    integrand = lambda z: (z - w) * f(z)\n",
    "    integral, error = quad(integrand, w, B)\n",
    "    \n",
    "    RHS = (β/(1-β))* integral\n",
    "    return LHS-RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419d49d5-6648-4f83-b8f3-a19b3ad51cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finiding w_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4923190-9fd2-4869-b2fe-59d0b402e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bar = fsolve(indifference, x0=0.5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb274fd-7e17-40e6-b623-e891e45e9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## closed-form value function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7950c586-428a-478b-aa82-0a8047cb868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_theory(w):\n",
    "    reject_value = w_bar/(1-β)\n",
    "    accept_value = w/(1-β)\n",
    "    index = (w> w_bar)*1.0\n",
    "    return (index*accept_value)+ ((1-index)*reject_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c688f2-797c-4f02-a827-e85ebdc9aa97",
   "metadata": {},
   "source": [
    "## Deep learning solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e96855-9e23-46b6-9553-971bc497e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376214d3-1edd-435c-aa00-a7a52aeb92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_hidden = 128,\n",
    "                layers = 2,\n",
    "                hidden_bias = True):\n",
    "        super().__init__()\n",
    "        self.dim_hidden= dim_hidden\n",
    "        self.layers = layers\n",
    "        self.hidden_bias = hidden_bias\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        module = []\n",
    "        module.append(nn.Linear(1,self.dim_hidden, bias = self.hidden_bias))\n",
    "        module.append(nn.ReLU())\n",
    "\n",
    "        for i in range(self.layers-1):\n",
    "            module.append(nn.Linear(self.dim_hidden,self.dim_hidden, bias = self.hidden_bias))\n",
    "            module.append(nn.Tanh())\n",
    "\n",
    "        module.append(nn.Linear(self.dim_hidden,1))\n",
    "        #module.append(nn.Softplus(beta = 1.0)) #The softplus layer ensures c>0,k>0\n",
    "\n",
    "        self.q = nn.Sequential(*module)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.q(x) # first element is consumption, the second element is capital\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae9915a9-cdb4-4d55-ac8a-311bcc04174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_v(model,a,b,n):\n",
    "    # model: the neural network (or any callable)\n",
    "    # a: lower bound of the unifrom distribution\n",
    "    # b: upper bound of the uniform distribution\n",
    "    # n: number of the nodes Gauss-legendre quadrature\n",
    "    nodes, weights = np.polynomial.legendre.leggauss(n)\n",
    "    nodes_tensor = torch.tensor(nodes, dtype=torch.float32).unsqueeze(-1)\n",
    "    weights_tensor = torch.tensor(weights, dtype=torch.float32).unsqueeze(-1)\n",
    "    adjusted_nodes = ((b - a) / 2) * nodes_tensor + ((a + b) / 2)\n",
    "    integral = ((b - a) / 2) * torch.sum(weights_tensor * model(adjusted_nodes))\n",
    "    expectation = integral/(b-a)\n",
    "    return expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9e6d97-4f70-4391-9d7b-d459966a74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training data and data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a9d9b3-eef8-467d-a4cb-1a3ebc134c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_data(B, epsilon, w_bar, step_size):\n",
    "    # full grid: 0, step_size, ..., B\n",
    "    w_full = torch.arange(0.0, B + step_size, step_size)\n",
    "\n",
    "    # exclude interval [(1-ε) * w_bar, (1+ε) * w_bar]\n",
    "    left_cutoff = (1 - epsilon) * w_bar\n",
    "    right_cutoff = (1 + epsilon) * w_bar\n",
    "    mask = (w_full < left_cutoff) | (w_full > right_cutoff)\n",
    "\n",
    "    w_grid_train = w_full[mask]\n",
    "    return w_grid_train.unsqueeze(1)\n",
    "\n",
    "\n",
    "train_data(B = B, epsilon = 0.0, w_bar = w_bar, step_size = 0.001).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51e306b-498f-4ad7-935a-6a6a94e101fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5001 # number of epochs\n",
    "\n",
    "print_epoch_frequency = 5000 # how often printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "304469ce-94f0-4697-8ee9-cb9a2befceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def training(epsilon, index):\n",
    "    # build training grid\n",
    "    w_grid_train = train_data(B=B, epsilon=epsilon, w_bar=w_bar, step_size=0.001)\n",
    "    data_loader = DataLoader(w_grid_train, batch_size=len(w_grid_train), shuffle=False)\n",
    "    \n",
    "    # initialize NN + optimizer\n",
    "    v_hat = NN()\n",
    "    learning_rate = 1e-2\n",
    "    optimizer = torch.optim.Adam(v_hat.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.95)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for w in data_loader:\n",
    "            optimizer.zero_grad() \n",
    "            lhs_v = v_hat(w)\n",
    "            v_employed = w / (1 - β)\n",
    "            v_unemployed = c + β * E_v(model=v_hat, a=0, b=B, n=50)\n",
    "            rhs_v = torch.max(v_employed, v_unemployed) \n",
    "            residual = lhs_v - rhs_v\n",
    "            loss = (residual ** 2).mean()\n",
    "        \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "        \n",
    "        scheduler.step() \n",
    "    \n",
    "        if epoch % print_epoch_frequency == 0:\n",
    "            print(f\"epoch = {epoch}, loss = {loss.detach().numpy():.2e}\")\n",
    "\n",
    "    # final evaluation grid\n",
    "    w_grid_test = torch.arange(0.0, B, 0.001).unsqueeze(1)\n",
    "    v_theory_test = v_theory(w_grid_test)\n",
    "    v_hat_test = v_hat(w_grid_test).detach()\n",
    "\n",
    "    # ---- save results to CSV ----\n",
    "    index_str = str(index).replace(\".\", \"_\")\n",
    "\n",
    "    # test results\n",
    "    df_test = pd.DataFrame({\n",
    "        \"w_test\": w_grid_test.squeeze().numpy(),\n",
    "        \"v_theory\": v_theory_test.squeeze().numpy(),\n",
    "        \"v_hat\": v_hat_test.squeeze().numpy()\n",
    "    })\n",
    "    df_test.to_csv(f\"training_results_eps_{index_str}_test.csv\", index=False)\n",
    "\n",
    "    # training grid\n",
    "    df_train = pd.DataFrame({\n",
    "        \"w_train\": w_grid_train.squeeze().numpy()\n",
    "    })\n",
    "    df_train.to_csv(f\"training_results_eps_{index_str}_train.csv\", index=False)\n",
    "\n",
    "    return v_theory_test, v_hat_test, w_grid_test, w_grid_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17ddb3c5-1321-4874-b3ce-366caeaf6cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 8.00e+00\n",
      "epoch = 5000, loss = 3.76e-06\n",
      "0.00% done\n",
      "epoch = 0, loss = 7.99e+00\n",
      "epoch = 5000, loss = 2.94e-06\n",
      "epoch = 0, loss = 7.97e+00\n",
      "epoch = 5000, loss = 2.07e-06\n",
      "epoch = 0, loss = 7.96e+00\n",
      "epoch = 5000, loss = 1.74e-06\n",
      "epoch = 0, loss = 7.95e+00\n",
      "epoch = 5000, loss = 1.43e-06\n",
      "epoch = 0, loss = 7.93e+00\n",
      "epoch = 5000, loss = 1.31e-06\n",
      "5.00% done\n",
      "epoch = 0, loss = 7.92e+00\n",
      "epoch = 5000, loss = 2.81e-06\n",
      "epoch = 0, loss = 7.90e+00\n",
      "epoch = 5000, loss = 3.03e-06\n",
      "epoch = 0, loss = 7.88e+00\n",
      "epoch = 5000, loss = 3.65e-06\n",
      "epoch = 0, loss = 7.87e+00\n",
      "epoch = 5000, loss = 4.30e-06\n",
      "epoch = 0, loss = 7.85e+00\n",
      "epoch = 5000, loss = 4.07e-06\n",
      "10.00% done\n",
      "epoch = 0, loss = 7.84e+00\n",
      "epoch = 5000, loss = 3.86e-06\n",
      "epoch = 0, loss = 7.82e+00\n",
      "epoch = 5000, loss = 2.28e-06\n",
      "epoch = 0, loss = 7.80e+00\n",
      "epoch = 5000, loss = 1.49e-06\n",
      "epoch = 0, loss = 7.79e+00\n",
      "epoch = 5000, loss = 1.47e-06\n",
      "epoch = 0, loss = 7.77e+00\n",
      "epoch = 5000, loss = 1.33e-06\n",
      "15.00% done\n",
      "epoch = 0, loss = 7.75e+00\n",
      "epoch = 5000, loss = 1.25e-06\n",
      "epoch = 0, loss = 7.74e+00\n",
      "epoch = 5000, loss = 1.20e-06\n",
      "epoch = 0, loss = 7.72e+00\n",
      "epoch = 5000, loss = 1.08e-06\n",
      "epoch = 0, loss = 7.69e+00\n",
      "epoch = 5000, loss = 1.03e-06\n",
      "epoch = 0, loss = 7.68e+00\n",
      "epoch = 5000, loss = 1.00e-06\n",
      "20.00% done\n",
      "epoch = 0, loss = 7.66e+00\n",
      "epoch = 5000, loss = 8.70e-07\n",
      "epoch = 0, loss = 7.65e+00\n",
      "epoch = 5000, loss = 7.75e-07\n",
      "epoch = 0, loss = 7.62e+00\n",
      "epoch = 5000, loss = 7.44e-07\n",
      "epoch = 0, loss = 7.60e+00\n",
      "epoch = 5000, loss = 2.99e-06\n",
      "epoch = 0, loss = 7.58e+00\n",
      "epoch = 5000, loss = 3.20e-06\n",
      "25.00% done\n",
      "epoch = 0, loss = 7.56e+00\n",
      "epoch = 5000, loss = 4.73e-06\n",
      "epoch = 0, loss = 7.53e+00\n",
      "epoch = 5000, loss = 4.67e-06\n",
      "epoch = 0, loss = 7.52e+00\n",
      "epoch = 5000, loss = 4.43e-06\n",
      "epoch = 0, loss = 7.49e+00\n",
      "epoch = 5000, loss = 4.12e-06\n",
      "epoch = 0, loss = 7.47e+00\n",
      "epoch = 5000, loss = 3.87e-06\n",
      "30.00% done\n",
      "epoch = 0, loss = 7.45e+00\n",
      "epoch = 5000, loss = 2.59e-06\n",
      "epoch = 0, loss = 7.42e+00\n",
      "epoch = 5000, loss = 2.38e-06\n",
      "epoch = 0, loss = 7.40e+00\n",
      "epoch = 5000, loss = 2.36e-06\n",
      "epoch = 0, loss = 7.37e+00\n",
      "epoch = 5000, loss = 2.32e-06\n",
      "epoch = 0, loss = 7.34e+00\n",
      "epoch = 5000, loss = 2.26e-06\n",
      "35.00% done\n",
      "epoch = 0, loss = 7.32e+00\n",
      "epoch = 5000, loss = 2.32e-06\n",
      "epoch = 0, loss = 7.29e+00\n",
      "epoch = 5000, loss = 2.35e-06\n",
      "epoch = 0, loss = 7.27e+00\n",
      "epoch = 5000, loss = 2.29e-06\n",
      "epoch = 0, loss = 7.24e+00\n",
      "epoch = 5000, loss = 2.36e-06\n",
      "epoch = 0, loss = 7.20e+00\n",
      "epoch = 5000, loss = 2.36e-06\n",
      "40.00% done\n",
      "epoch = 0, loss = 7.18e+00\n",
      "epoch = 5000, loss = 2.34e-06\n",
      "epoch = 0, loss = 7.15e+00\n",
      "epoch = 5000, loss = 2.36e-06\n",
      "epoch = 0, loss = 7.10e+00\n",
      "epoch = 5000, loss = 2.36e-06\n",
      "epoch = 0, loss = 7.09e+00\n",
      "epoch = 5000, loss = 2.38e-06\n",
      "epoch = 0, loss = 7.05e+00\n",
      "epoch = 5000, loss = 2.37e-06\n",
      "45.00% done\n",
      "epoch = 0, loss = 7.03e+00\n",
      "epoch = 5000, loss = 2.35e-06\n",
      "epoch = 0, loss = 6.98e+00\n",
      "epoch = 5000, loss = 2.31e-06\n",
      "epoch = 0, loss = 6.94e+00\n",
      "epoch = 5000, loss = 2.29e-06\n",
      "epoch = 0, loss = 6.92e+00\n",
      "epoch = 5000, loss = 2.16e-06\n",
      "epoch = 0, loss = 6.87e+00\n",
      "epoch = 5000, loss = 1.44e-06\n",
      "50.00% done\n",
      "epoch = 0, loss = 6.82e+00\n",
      "epoch = 5000, loss = 1.69e-06\n",
      "epoch = 0, loss = 6.80e+00\n",
      "epoch = 5000, loss = 1.70e-06\n",
      "epoch = 0, loss = 6.75e+00\n",
      "epoch = 5000, loss = 1.62e-06\n",
      "epoch = 0, loss = 6.73e+00\n",
      "epoch = 5000, loss = 1.55e-06\n",
      "epoch = 0, loss = 6.68e+00\n",
      "epoch = 5000, loss = 1.42e-06\n",
      "55.00% done\n",
      "epoch = 0, loss = 6.62e+00\n",
      "epoch = 5000, loss = 1.29e-06\n",
      "epoch = 0, loss = 6.60e+00\n",
      "epoch = 5000, loss = 1.23e-06\n",
      "epoch = 0, loss = 6.54e+00\n",
      "epoch = 5000, loss = 1.10e-06\n",
      "epoch = 0, loss = 6.48e+00\n",
      "epoch = 5000, loss = 9.80e-07\n",
      "epoch = 0, loss = 6.45e+00\n",
      "epoch = 5000, loss = 9.07e-07\n",
      "60.00% done\n",
      "epoch = 0, loss = 6.39e+00\n",
      "epoch = 5000, loss = 7.87e-07\n",
      "epoch = 0, loss = 6.36e+00\n",
      "epoch = 5000, loss = 7.46e-07\n",
      "epoch = 0, loss = 6.29e+00\n",
      "epoch = 5000, loss = 6.52e-07\n",
      "epoch = 0, loss = 6.22e+00\n",
      "epoch = 5000, loss = 5.69e-07\n",
      "epoch = 0, loss = 6.19e+00\n",
      "epoch = 5000, loss = 5.33e-07\n",
      "65.00% done\n",
      "epoch = 0, loss = 6.12e+00\n",
      "epoch = 5000, loss = 4.95e-07\n",
      "epoch = 0, loss = 6.04e+00\n",
      "epoch = 5000, loss = 4.27e-07\n",
      "epoch = 0, loss = 6.01e+00\n",
      "epoch = 5000, loss = 3.88e-07\n",
      "epoch = 0, loss = 5.93e+00\n",
      "epoch = 5000, loss = 2.94e-07\n",
      "epoch = 0, loss = 5.89e+00\n",
      "epoch = 5000, loss = 2.59e-07\n",
      "70.00% done\n",
      "epoch = 0, loss = 5.81e+00\n",
      "epoch = 5000, loss = 2.23e-07\n",
      "epoch = 0, loss = 5.72e+00\n",
      "epoch = 5000, loss = 2.34e-07\n",
      "epoch = 0, loss = 5.68e+00\n",
      "epoch = 5000, loss = 2.50e-07\n",
      "epoch = 0, loss = 5.59e+00\n",
      "epoch = 5000, loss = 3.15e-07\n",
      "epoch = 0, loss = 5.49e+00\n",
      "epoch = 5000, loss = 3.59e-07\n",
      "75.00% done\n",
      "epoch = 0, loss = 5.45e+00\n",
      "epoch = 5000, loss = 4.67e-07\n",
      "epoch = 0, loss = 5.35e+00\n",
      "epoch = 5000, loss = 7.11e-07\n",
      "epoch = 0, loss = 5.30e+00\n",
      "epoch = 5000, loss = 8.54e-07\n",
      "epoch = 0, loss = 5.20e+00\n",
      "epoch = 5000, loss = 1.43e-06\n",
      "epoch = 0, loss = 5.08e+00\n",
      "epoch = 5000, loss = 1.22e-06\n",
      "80.00% done\n",
      "epoch = 0, loss = 5.03e+00\n",
      "epoch = 5000, loss = 1.08e-06\n",
      "epoch = 0, loss = 4.91e+00\n",
      "epoch = 5000, loss = 9.34e-07\n",
      "epoch = 0, loss = 4.79e+00\n",
      "epoch = 5000, loss = 4.85e-07\n",
      "epoch = 0, loss = 4.73e+00\n",
      "epoch = 5000, loss = 3.78e-07\n",
      "epoch = 0, loss = 4.60e+00\n",
      "epoch = 5000, loss = 7.03e-07\n",
      "85.00% done\n",
      "epoch = 0, loss = 4.53e+00\n",
      "epoch = 5000, loss = 7.21e-07\n",
      "epoch = 0, loss = 4.40e+00\n",
      "epoch = 5000, loss = 4.80e-07\n",
      "epoch = 0, loss = 4.25e+00\n",
      "epoch = 5000, loss = 2.89e-07\n",
      "epoch = 0, loss = 4.18e+00\n",
      "epoch = 5000, loss = 2.65e-07\n",
      "epoch = 0, loss = 4.02e+00\n",
      "epoch = 5000, loss = 1.78e-07\n",
      "90.00% done\n",
      "epoch = 0, loss = 3.86e+00\n",
      "epoch = 5000, loss = 1.01e-07\n",
      "epoch = 0, loss = 3.78e+00\n",
      "epoch = 5000, loss = 4.12e-07\n",
      "epoch = 0, loss = 3.60e+00\n",
      "epoch = 5000, loss = 2.79e-08\n",
      "epoch = 0, loss = 3.51e+00\n",
      "epoch = 5000, loss = 2.84e-08\n",
      "epoch = 0, loss = 3.33e+00\n",
      "epoch = 5000, loss = 1.45e-08\n",
      "95.00% done\n",
      "epoch = 0, loss = 3.13e+00\n",
      "epoch = 5000, loss = 1.39e-08\n",
      "epoch = 0, loss = 3.03e+00\n",
      "epoch = 5000, loss = 1.23e-08\n",
      "epoch = 0, loss = 2.82e+00\n",
      "epoch = 5000, loss = 1.39e-08\n",
      "epoch = 0, loss = 2.60e+00\n",
      "epoch = 5000, loss = 4.79e-08\n"
     ]
    }
   ],
   "source": [
    "## Saving the results\n",
    "epsilon_grid = torch.arange(0.0,0.5,0.005)\n",
    "for i, eps in enumerate(epsilon_grid):\n",
    "    idx = len(epsilon_grid) - 1 - i\n",
    "    v_theory_test, v_hat_test, w_grid_test, w_grid_train = training(epsilon=eps, index = idx)\n",
    "    \n",
    "    if i % 5 == 0:  # print every 5th iteration\n",
    "        progress = (i / epsilon_grid.shape[0]) * 100\n",
    "        print(f\"{progress:.2f}% done\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d3341-e2c9-4b0e-a3ec-f4b0288840ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
